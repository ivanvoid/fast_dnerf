{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-genetic-opt in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (0.24.2)\n",
      "Requirement already satisfied: seaborn>=0.11.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (0.11.2)\n",
      "Requirement already satisfied: deap>=1.3.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (1.19.5)\n",
      "Requirement already satisfied: pydantic>=1.8.2 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (1.9.2)\n",
      "Requirement already satisfied: dataclasses>=0.6 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from pydantic>=1.8.2->sklearn-genetic-opt) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from pydantic>=1.8.2->sklearn-genetic-opt) (4.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from scikit-learn>=0.21.3->sklearn-genetic-opt) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from scikit-learn>=0.21.3->sklearn-genetic-opt) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from scikit-learn>=0.21.3->sklearn-genetic-opt) (1.1.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from seaborn>=0.11.1->sklearn-genetic-opt) (3.3.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from seaborn>=0.11.1->sklearn-genetic-opt) (1.1.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from pandas>=0.23->seaborn>=0.11.1->sklearn-genetic-opt) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-genetic-opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search one parameter optimization\n",
    "Example, make sure it works before going to GA.  \n",
    "\n",
    "Score computes with MSE loss and PSNR like:  \n",
    "$$score = 1-MSE + PSNR/100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDNeRF(BaseEstimator, RegressorMixin):  \n",
    "    def __init__(self, n_layers=0):\n",
    "        # Parameters should have same name as attributes\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        command = 'python run_nerf.py --config configs/lego.txt --n_iters 100'\n",
    "        command += ' --n_layers '+ str(self.n_layers)\n",
    "        command += ' --n_layers_fine '+str(self.n_layers)\n",
    "        command += ' --i_print '+str(20)\n",
    "        \n",
    "        print(command)\n",
    "        p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "        (output, err) = p.communicate()  \n",
    "\n",
    "        #This makes the wait possible\n",
    "        p_status = p.wait()\n",
    "        # print('Training done')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"treshold_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        train_dirs = sorted(os.listdir('logs'))\n",
    "        train_dirs.remove('summaries')\n",
    "        train_dirs_split = [x.split(' ')[1] for x in train_dirs]\n",
    "        inexies = [i[0] for i in sorted(enumerate(train_dirs_split), key=lambda x:x[1])]\n",
    "        mask = np.array(inexies) == max(inexies)\n",
    "        file_name = np.array(train_dirs)[mask]\n",
    "\n",
    "        last_train_file = 'logs/' + file_name[0] + '/loss_vs_time.pkl'\n",
    "\n",
    "        data = np.load(last_train_file, allow_pickle=True)\n",
    "        loss,psnr,time = data['losses'][-1], data['psnr'][-1], data['time'][-1]\n",
    "        score = 1-loss + psnr/100\n",
    "        print(f'score: {score}')\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "N = 3\n",
    "X_train = np.linspace(1, 3, num=N)\n",
    "X_test = np.linspace(1, 3, num=N)\n",
    "dummy_y = [1 for i in range(N)]\n",
    "tuned_params = {\n",
    "    \"n_layers\" : np.array([1, 2, 8]).astype(int)\n",
    "    }\n",
    "\n",
    "\n",
    "gs = GridSearchCV(FDNeRF(), tuned_params, cv=[(slice(None), slice(None))])\n",
    "\n",
    "# for some reason I have to pass y with same shape\n",
    "# otherwise gridsearch throws an error. Not sure why.\n",
    "# X and Y dosn't mean anything\n",
    "# just makecompatable with sklearn\n",
    "gs.fit(X_test, y=dummy_y)\n",
    "\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Optimization \n",
    "Parameter list:\n",
    "- n_layers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDNeRF_GA(BaseEstimator, RegressorMixin):  \n",
    "    def __init__(self, \n",
    "                 n_layers=0,\n",
    "                 n_width=0,\n",
    "                 n_layers_fine=0,\n",
    "                 n_width_fine=0,\n",
    "                 n_layers_time=0,\n",
    "                 n_width_time=0,\n",
    "                 multires=0,\n",
    "                 multires_timenet=0,\n",
    "                 ):\n",
    "        # Parameters should have same name as attributes\n",
    "        self.n_layers=n_layers\n",
    "        self.n_width=n_width\n",
    "        self.n_layers_fine=n_layers_fine\n",
    "        self.n_width_fine=n_width_fine\n",
    "        self.n_layers_time=n_layers_time\n",
    "        self.n_width_time=n_width_time\n",
    "        self.multires=multires\n",
    "        self.multires_timenet=multires_timenet\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        command = 'python run_nerf.py --config configs/lego.txt --n_iters 100'\n",
    "        command += ' --n_layers '+ str(self.n_layers)\n",
    "        command += ' --n_layers_fine '+str(self.n_layers_fine)\n",
    "        # command += ' --n_width '+str(self.n_width)\n",
    "        \n",
    "        command += ' --i_print '+str(20)\n",
    "        \n",
    "        print(command)\n",
    "        p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "        (output, err) = p.communicate()  \n",
    "\n",
    "        #This makes the wait possible\n",
    "        p_status = p.wait()\n",
    "        # print('Training done')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"treshold_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        train_dirs = sorted(os.listdir('logs'))\n",
    "        train_dirs.remove('summaries')\n",
    "        train_dirs_split = [x.split(' ')[1] for x in train_dirs]\n",
    "        inexies = [i[0] for i in sorted(enumerate(train_dirs_split), key=lambda x:x[1])]\n",
    "        mask = np.array(inexies) == max(inexies)\n",
    "        file_name = np.array(train_dirs)[mask]\n",
    "\n",
    "        last_train_file = 'logs/' + file_name[0] + '/loss_vs_time.pkl'\n",
    "\n",
    "        data = np.load(last_train_file, allow_pickle=True)\n",
    "        loss,psnr,time = data['losses'][-1], data['psnr'][-1], data['time'][-1]\n",
    "        score = 1-loss + psnr/100\n",
    "        print(f'score: {score}')\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical, Continuous,Integer\n",
    "# https://sklearn-genetic-opt.readthedocs.io/en/stable/api/space.html\n",
    "param_grid = {\n",
    "    \"n_layers\" : Integer(1,8),\n",
    "    \"n_layers_fine\" : Integer(1,8),\n",
    "    \n",
    "    }\n",
    "\n",
    "evolved_estimator = GASearchCV(FDNeRF_GA(),\n",
    "                    cv=[(slice(None), slice(None))],\n",
    "                    # scoring='accuracy',\n",
    "                    param_grid=param_grid,\n",
    "                    population_size=2,\n",
    "                    generations=3,\n",
    "                    tournament_size=3,\n",
    "                    elitism=True,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 3 --i_print 20\n",
      "score: 1.0385154968500137\n",
      "gen\tnevals\tfitness\tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t2     \t1.02356\t0.01496    \t1.03852    \t1.0086     \n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 3 --i_print 20\n",
      "score: 1.0385154968500137\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 3 --i_print 20\n",
      "score: 1.0385154968500137\n",
      "1  \t4     \t1.0086 \t0          \t1.0086     \t1.0086     \n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "2  \t4     \t1.0086 \t0          \t1.0086     \t1.0086     \n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 8 --i_print 20\n",
      "score: 0.9761465269327163\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 4 --i_print 20\n",
      "score: 1.008595460653305\n",
      "3  \t3     \t1.0086 \t0          \t1.0086     \t1.0086     \n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_layers_fine 3 --i_print 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn_genetic.genetic_search.GASearchCV at 0x7ba96f2fa198>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 3\n",
    "dummy_x = np.linspace(1, 3, num=N)\n",
    "dummy_y = [1 for i in range(N)]\n",
    "\n",
    "evolved_results = evolved_estimator.fit(dummy_x,dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_layers': 4, 'n_layers_fine': 3}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evolved_estimator.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
