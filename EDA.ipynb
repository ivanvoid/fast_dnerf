{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn-genetic-opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search one parameter optimization\n",
    "Example, make sure it works before going to GA.  \n",
    "\n",
    "Score computes with MSE loss and PSNR like:  \n",
    "$$score = 1-MSE + PSNR/100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDNeRF(BaseEstimator, RegressorMixin):  \n",
    "    def __init__(self, n_layers=0):\n",
    "        # Parameters should have same name as attributes\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        command = 'python run_nerf.py --config configs/lego.txt --n_iters 100'\n",
    "        command += ' --n_layers '+ str(self.n_layers)\n",
    "        command += ' --n_layers_fine '+str(self.n_layers)\n",
    "        command += ' --i_print '+str(20)\n",
    "        \n",
    "        print(command)\n",
    "        p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "        (output, err) = p.communicate()  \n",
    "\n",
    "        #This makes the wait possible\n",
    "        p_status = p.wait()\n",
    "        # print('Training done')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"treshold_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        train_dirs = sorted(os.listdir('logs'))\n",
    "        train_dirs.remove('summaries')\n",
    "        train_dirs_split = [x.split(' ')[1] for x in train_dirs]\n",
    "        inexies = [i[0] for i in sorted(enumerate(train_dirs_split), key=lambda x:x[1])]\n",
    "        mask = np.array(inexies) == max(inexies)\n",
    "        file_name = np.array(train_dirs)[mask]\n",
    "\n",
    "        last_train_file = 'logs/' + file_name[0] + '/loss_vs_time.pkl'\n",
    "\n",
    "        data = np.load(last_train_file, allow_pickle=True)\n",
    "        loss,psnr,time = data['losses'][-1], data['psnr'][-1], data['time'][-1]\n",
    "        score = 1-loss + psnr/100\n",
    "        print(f'score: {score}')\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "N = 3\n",
    "X_train = np.linspace(1, 3, num=N)\n",
    "X_test = np.linspace(1, 3, num=N)\n",
    "dummy_y = [1 for i in range(N)]\n",
    "tuned_params = {\n",
    "    \"n_layers\" : np.array([1, 2, 8]).astype(int)\n",
    "    }\n",
    "\n",
    "\n",
    "gs = GridSearchCV(FDNeRF(), tuned_params, cv=[(slice(None), slice(None))])\n",
    "\n",
    "# for some reason I have to pass y with same shape\n",
    "# otherwise gridsearch throws an error. Not sure why.\n",
    "# X and Y dosn't mean anything\n",
    "# just makecompatable with sklearn\n",
    "gs.fit(X_test, y=dummy_y)\n",
    "\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Optimization \n",
    "Parameter list:\n",
    "- n_layers: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDNeRF_GA(BaseEstimator, RegressorMixin):  \n",
    "    def __init__(self, \n",
    "                 n_layers=0,\n",
    "                 n_width=0,\n",
    "                 n_layers_fine=0,\n",
    "                 n_width_fine=0,\n",
    "                 n_layers_time=0,\n",
    "                 n_width_time=0,\n",
    "                 multires=0,\n",
    "                 multires_timenet=0,\n",
    "                 ):\n",
    "        # Parameters should have same name as attributes\n",
    "        self.n_layers=n_layers\n",
    "        self.n_width=n_width\n",
    "        self.n_layers_fine=n_layers_fine\n",
    "        self.n_width_fine=n_width_fine\n",
    "        self.n_layers_time=n_layers_time\n",
    "        self.n_width_time=n_width_time\n",
    "        self.multires=multires\n",
    "        self.multires_timenet=multires_timenet\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        command = 'python run_nerf.py --config configs/lego.txt --n_iters 100'\n",
    "        \n",
    "        command += ' --n_layers '+ str(self.n_layers)\n",
    "        command += ' --n_width '+str(self.n_width)\n",
    "        \n",
    "        command += ' --n_layers_fine '+str(self.n_layers_fine)\n",
    "        command += ' --n_width_fine '+str(self.n_width_fine)\n",
    "\n",
    "        command += ' --n_layers_fine '+str(self.n_layers_fine)\n",
    "        command += ' --n_width_fine '+str(self.n_width_fine)\n",
    "        \n",
    "        command += ' --i_print '+str(20)\n",
    "        \n",
    "        print(command)\n",
    "        p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "        (output, err) = p.communicate()  \n",
    "\n",
    "        #This makes the wait possible\n",
    "        p_status = p.wait()\n",
    "        # print('Training done')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"treshold_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def _compute_score(self,data):\n",
    "        psnr = np.array(data['psnr']) \n",
    "        rev_time = np.array(data['time'])[::-1] # reversed\n",
    "        _psnr = (psnr / rev_time).sum()\n",
    "\n",
    "        loss = (1 - np.array(data['losses'])) / rev_time\n",
    "        _loss = loss.sum()*10\n",
    "        score =_psnr + _loss\n",
    "        return score\n",
    "\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        train_dirs = sorted(os.listdir('logs'))\n",
    "        train_dirs.remove('summaries')\n",
    "        train_dirs_split = [x.split(' ')[1] for x in train_dirs]\n",
    "        inexies = [i[0] for i in sorted(enumerate(train_dirs_split), key=lambda x:x[1])]\n",
    "        mask = np.array(inexies) == max(inexies)\n",
    "        file_name = np.array(train_dirs)[mask]\n",
    "\n",
    "        last_train_file = 'logs/' + file_name[0] + '/loss_vs_time.pkl'\n",
    "\n",
    "        data = np.load(last_train_file, allow_pickle=True)\n",
    "        # loss,psnr,time = data['losses'][-1], data['psnr'][-1], data['time'][-1]\n",
    "        # score = 1-loss + psnr/100\n",
    "        score = self._compute_score(data)\n",
    "        print(f'score: {score}')\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic import GASearchCV\n",
    "from sklearn_genetic.space import Categorical, Continuous,Integer\n",
    "# https://sklearn-genetic-opt.readthedocs.io/en/stable/api/space.html\n",
    "param_grid = {\n",
    "    \"n_layers\" : Integer(1,8),\n",
    "    \"n_layers_fine\" : Integer(1,8),\n",
    "    \n",
    "    }\n",
    "\n",
    "evolved_estimator = GASearchCV(FDNeRF_GA(),\n",
    "                    cv=[(slice(None), slice(None))],\n",
    "                    # scoring='accuracy',\n",
    "                    param_grid=param_grid,\n",
    "                    population_size=3,\n",
    "                    generations=3,\n",
    "                    tournament_size=3,\n",
    "                    elitism=True,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_width 0 --n_layers_fine 1 --n_width_fine 0 --n_layers_fine 1 --n_width_fine 0 --i_print 20\n",
      "score: 10.48780272536377\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 3 --n_width 0 --n_layers_fine 1 --n_width_fine 0 --n_layers_fine 1 --n_width_fine 0 --i_print 20\n",
      "score: 10.38626243462603\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 1 --n_width 0 --n_layers_fine 5 --n_width_fine 0 --n_layers_fine 5 --n_width_fine 0 --i_print 20\n",
      "score: 11.487921050098445\n",
      "gen\tnevals\tfitness\tfitness_std\tfitness_max\tfitness_min\n",
      "0  \t3     \t10.7873\t0.497125   \t11.4879    \t10.3863    \n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 3 --n_width 0 --n_layers_fine 1 --n_width_fine 0 --n_layers_fine 1 --n_width_fine 0 --i_print 20\n",
      "score: 10.523050268722134\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 1 --n_width 0 --n_layers_fine 1 --n_width_fine 0 --n_layers_fine 1 --n_width_fine 0 --i_print 20\n",
      "score: 11.110609408302818\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 1 --n_width 0 --n_layers_fine 1 --n_width_fine 0 --n_layers_fine 1 --n_width_fine 0 --i_print 20\n",
      "score: 11.057750784423131\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 4 --n_width 0 --n_layers_fine 1 --n_width_fine 0 --n_layers_fine 1 --n_width_fine 0 --i_print 20\n",
      "score: 10.69807994877941\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 1 --n_width 0 --n_layers_fine 1 --n_width_fine 0 --n_layers_fine 1 --n_width_fine 0 --i_print 20\n",
      "score: 11.255209285802287\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 3 --n_width 0 --n_layers_fine 5 --n_width_fine 0 --n_layers_fine 5 --n_width_fine 0 --i_print 20\n"
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "dummy_x = np.linspace(1, 3, num=N)\n",
    "dummy_y = [1 for i in range(N)]\n",
    "\n",
    "evolved_results = evolved_estimator.fit(dummy_x,dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolved_estimator.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
