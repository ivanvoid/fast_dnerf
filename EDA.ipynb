{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-genetic-opt in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (0.3.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (0.24.2)\n",
      "Requirement already satisfied: seaborn>=0.11.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (0.11.2)\n",
      "Requirement already satisfied: deap>=1.3.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (1.19.5)\n",
      "Requirement already satisfied: pydantic>=1.8.2 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from sklearn-genetic-opt) (1.9.2)\n",
      "Requirement already satisfied: dataclasses>=0.6 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from pydantic>=1.8.2->sklearn-genetic-opt) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from pydantic>=1.8.2->sklearn-genetic-opt) (4.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from scikit-learn>=0.21.3->sklearn-genetic-opt) (3.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from scikit-learn>=0.21.3->sklearn-genetic-opt) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from scikit-learn>=0.21.3->sklearn-genetic-opt) (1.1.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from seaborn>=0.11.1->sklearn-genetic-opt) (3.3.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from seaborn>=0.11.1->sklearn-genetic-opt) (1.1.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from pandas>=0.23->seaborn>=0.11.1->sklearn-genetic-opt) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/ivan/miniconda3/envs/dnerf/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn>=0.11.1->sklearn-genetic-opt) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-genetic-opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "### RUN MODEL\n",
    "import subprocess\n",
    "\n",
    "command = 'python run_nerf.py --config configs/lego.txt --n_iters 100'\n",
    "p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "(output, err) = p.communicate()  \n",
    "\n",
    "#This makes the wait possible\n",
    "p_status = p.wait()\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764846938848495"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET EVALUATION DATA\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "train_dirs = sorted(os.listdir('logs'))\n",
    "train_dirs.remove('summaries')\n",
    "train_dirs_split = [x.split(' ')[1] for x in train_dirs]\n",
    "inexies = [i[0] for i in sorted(enumerate(train_dirs_split), key=lambda x:x[1])]\n",
    "mask = np.array(inexies) == max(inexies)\n",
    "file_name = np.array(train_dirs)[mask]\n",
    "\n",
    "last_train_file = 'logs/' + file_name[0] + '/loss_vs_time.pkl'\n",
    "\n",
    "data = np.load(last_train_file, allow_pickle=True)\n",
    "loss,psnr,time = data['losses'][-1], data['psnr'][-1], data['time'][-1]\n",
    "score = 1-loss + psnr/100\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in train_dirs:\n",
    "#     last_train_file = 'logs/' + p + '/loss_vs_time.pkl'\n",
    "\n",
    "#     data = np.load(last_train_file, allow_pickle=True)\n",
    "#     loss,psnr,time = data['losses'][-1], data['psnr'][-1], data['time'][-1]\n",
    "#     score = 1-loss + psnr/100\n",
    "#     print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False,  True, False])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [\n",
    " '062024-06-28 14:03:22',\n",
    " '062024-06-28 14:02:52',\n",
    " '062024-06-28 14:01:55',\n",
    " '062024-06-28 14:02:23',\n",
    " '062024-06-28 13:41:16',\n",
    " '062024-06-28 14:01:26',\n",
    " '062024-06-28 14:03:24']\n",
    "inexies = [i[0] for i in sorted(enumerate(a), key=lambda x:x[1])]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class FDNeRF(BaseEstimator):  \n",
    "    def __init__(self, n_layers=0):\n",
    "        \"\"\"\n",
    "        Called when initializing the classifier\n",
    "        \"\"\"\n",
    "        # Parameters should have same name as attributes\n",
    "        self.n_layers = n_layers\n",
    "        # self.stringParam = stringParam\n",
    "        # self.otherParam = otherParam \n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        ''' Fit model\n",
    "        '''\n",
    "        command = 'python run_nerf.py --config configs/lego.txt --n_iters 100'\n",
    "        command += ' --n_layers '+ str(self.n_layers)\n",
    "        command += ' --n_layers_fine '+str(self.n_layers)\n",
    "        command += ' --i_print '+str(20)\n",
    "        \n",
    "        \n",
    "        print(command)\n",
    "        p = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "        (output, err) = p.communicate()  \n",
    "\n",
    "        #This makes the wait possible\n",
    "        p_status = p.wait()\n",
    "        # print('Training done')\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        try:\n",
    "            getattr(self, \"treshold_\")\n",
    "        except AttributeError:\n",
    "            raise RuntimeError(\"You must train classifer before predicting data!\")\n",
    "\n",
    "        return self.result\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        train_dirs = sorted(os.listdir('logs'))\n",
    "        train_dirs.remove('summaries')\n",
    "        train_dirs_split = [x.split(' ')[1] for x in train_dirs]\n",
    "        inexies = [i[0] for i in sorted(enumerate(train_dirs_split), key=lambda x:x[1])]\n",
    "        mask = np.array(inexies) == max(inexies)\n",
    "        file_name = np.array(train_dirs)[mask]\n",
    "\n",
    "        last_train_file = 'logs/' + file_name[0] + '/loss_vs_time.pkl'\n",
    "\n",
    "        data = np.load(last_train_file, allow_pickle=True)\n",
    "        loss,psnr,time = data['losses'][-1], data['psnr'][-1], data['time'][-1]\n",
    "        score = 1-loss + psnr/100\n",
    "        print(f'N: {self.n_layers} score: {score}')\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 1 --n_layers_fine 1 --i_print 20\n",
      "N: 1 score: 0.9764846938848495\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 5 --n_layers_fine 5 --i_print 20\n",
      "N: 5 score: 0.9379014140367508\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 10 --n_layers_fine 10 --i_print 20\n",
      "N: 10 score: 0.9571131694316863\n",
      "python run_nerf.py --config configs/lego.txt --n_iters 100 --n_layers 1 --n_layers_fine 1 --i_print 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_layers': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "N = 3\n",
    "X_train = np.linspace(1, 3, num=N)\n",
    "X_test = np.linspace(1, 3, num=N)\n",
    "dummy_y = [1 for i in range(N)]\n",
    "tuned_params = {\n",
    "    \"n_layers\" : np.array([1, 2, 8]).astype(int)\n",
    "    }\n",
    "\n",
    "\n",
    "gs = GridSearchCV(FDNeRF(), tuned_params, cv=[(slice(None), slice(None))])\n",
    "\n",
    "# for some reason I have to pass y with same shape\n",
    "# otherwise gridsearch throws an error. Not sure why.\n",
    "# X and Y dosn't mean anything\n",
    "# just makecompatable with sklearn\n",
    "gs.fit(X_test, y=dummy_y)\n",
    "\n",
    "gs.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intValue': -10}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "X_train = [i for i in range(0, 100, 5)]  \n",
    "X_test = [i + 3 for i in range(-5, 95, 5)]  \n",
    "tuned_params = {\"intValue\" : [-10,-1,0,1,10]}\n",
    "\n",
    "gs = GridSearchCV(MeanClassifier(), tuned_params)\n",
    "\n",
    "# for some reason I have to pass y with same shape\n",
    "# otherwise gridsearch throws an error. Not sure why.\n",
    "gs.fit(X_test, y=[1 for i in range(20)])\n",
    "\n",
    "gs.best_params_ # {'intValue': -10} # and that is what we expect :)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_genetic import GASearchCV\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "# from sklearn_genetic.space import Categorical, Continuous\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "# from sklearn.datasets import load_digits\n",
    "# from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot clone object '<__main__.Estimator object at 0x73079ea5a208>' (type <class '__main__.Estimator'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-baed74c933b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/dnerf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnerf/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         \u001b[0mbase_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         parallel = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[0;32m~/miniconda3/envs/dnerf/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dnerf/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     69\u001b[0m                                 \u001b[0;34m\"estimator as it does not implement a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m                                 \u001b[0;34m\"'get_params' method.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                                 % (repr(estimator), type(estimator)))\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot clone object '<__main__.Estimator object at 0x73079ea5a208>' (type <class '__main__.Estimator'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method."
     ]
    }
   ],
   "source": [
    "param_dist = {'average': [True, False],\n",
    "              'l1_ratio': stats.uniform(0, 1),\n",
    "              'alpha': loguniform(1e-4, 1e0)}\n",
    "n_iter_search = 30\n",
    "\n",
    "random_search = RandomizedSearchCV(e, \n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "X = 'a'\n",
    "Y = 'b'\n",
    "random_search.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-99ae44458e28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32*4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnerf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
